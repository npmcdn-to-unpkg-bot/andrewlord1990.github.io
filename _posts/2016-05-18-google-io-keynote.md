---
layout: inner
title: 'Google IO: Keynote Highlights'
date: 2016-05-18
categories: dev android google-io
tags: blog dev google-io conference apps announcements android
lead_text: 'Highlights of the Keynote speech from Google IO 2016 at the Shoreline Amphitheatre, Mountain View, California.'
featured_image: 'posts/google-io-2016/keynote-featured.jpg'
---

Google IO 2016 takes place at the Shoreline Amphitheatre, Mountain View, California, very close to the Googleplex. The conference kicked off with an exciting and announcement-packed keynote speech, delivered by various Googlers, starting with the Google CEO Sundar Pichai.

The keynote speech began at 10a.m. PT (UTC-8), for which I was lucky enough to get a seat right at the front, in one of the first few rows. The venue itself is outside, with an awning covering the front seating areas. Behind and to the sides of the stage were 3 huge high-definition screens. Whilst the audience was waiting for the keynote to being, various videos and games requiring audience participation were presented across the screens.

{% include post-row-images.html
            img0="posts/google-io-2016/keynote-planes-game.jpg"
            title0="Interactive planes game"
            caption0="Game which allowed audience members to fly a paper pane using their phone's sensors."
            img1="posts/google-io-2016/keynote-paint-game.jpg"
            title1="Interactive paint game"
            caption1="A game which allowed audience members to flick their device to throw paint at the IO logo." %}

### Introduction

The keynote kicked off which a segment discussing how since Google formed increasing numbers of people are coming online and that there is a huge shift of usage to mobile devices.

- 3 billion people are now connected to the internet, globally.
- 50% of Google queries now come from mobile devices
- 20% of Google queries are voice searches

Google's focus is on improving how they can improve users' lives, make everyday tasks easier and provide relevant content and suggestions. Rather than just showing links, Google search now shows content directly in the search results. They now have an understanding of over 1 billion entities - people, places and things. Using this information and machine learning, Google can understand context, to provide more accurate and useful information to users. Sundar then showed an example of the Photos app showing all the pictures of hugs and of dogs on the user's device. He then went on to show real time translation from English to Chinese directly in the camera feed, by aiming the camera at a sign written in English.

{% include post-image.html
            img="posts/google-io-2016/keynote-stage-start.jpg"
            title="Start of keynote speech"
            caption="Start of keynote speech" %}
